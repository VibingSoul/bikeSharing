{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all relevant and necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Comprehending the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_dataframe = pd.read_csv(r'D:\\UPGRAD\\Case_Study\\BoomBikes\\day.csv')\n",
    "bike_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for shape of the dataset\n",
    "bike_dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gather information about data\n",
    "#Checking for count and the type of data present in the given dataset\n",
    "bike_dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_dataframe.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values\n",
    "bike_dataframe.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As part of data cleaning, dropping following columns\n",
    "- instant: since it is merely index of every record in the dataset\n",
    "- dteday: this information of date is also available in year, month columns\n",
    "- casual and registered: since 'cnt' column has summation of these two values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_dataframe.drop(['instant','dteday','casual','registered'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the duplicates\n",
    "bike_dataframe.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As the shape remains after dropping duplicates, which indicates that there are no duplicates in the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing categorical data which were primarily numeric to more meaningful one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding/mapping the season column\n",
    "\n",
    "bike_dataframe.season = bike_dataframe.season.map({1:'spring', 2:'summer', 3:'fall', 4:'winter'})\n",
    "\n",
    "# Encoding/mapping the month column\n",
    "\n",
    "bike_dataframe.mnth = bike_dataframe.mnth.map({1:'jan',2:'feb',3:'mar',4:'apr',5:'may',6:'june',7:'july',8:'aug',9:'sep',10:'oct',11:'nov',12:'dec'})\n",
    "\n",
    "# Encoding/mapping the weekday column\n",
    "\n",
    "bike_dataframe.weekday = bike_dataframe.weekday.map({0:'sun',1:'mon',2:'tue',3:'wed',4:'thu',5:'fri',6:'sat'})\n",
    "\n",
    "# Encoding/mapping the weathersit column\n",
    "\n",
    "bike_dataframe.weathersit = bike_dataframe.weathersit.map({1:'Clear',2:'Misty',3:'Light_snowrain',4:'Heavy_snowrain'})\n",
    "\n",
    "bike_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysing/visualizing the categorical columns\n",
    "# to see how predictor variable stands against the target variable\n",
    "\n",
    "plt.figure(figsize=(20, 12))\n",
    "plt.subplot(2,4,1)\n",
    "sns.boxplot(x = 'season', y = 'cnt', data = bike_dataframe)\n",
    "plt.subplot(2,4,2)\n",
    "sns.boxplot(x = 'mnth', y = 'cnt', data = bike_dataframe)\n",
    "plt.subplot(2,4,3)\n",
    "sns.boxplot(x = 'weekday', y = 'cnt', data = bike_dataframe)\n",
    "plt.subplot(2,4,4)\n",
    "sns.boxplot(x = 'weathersit', y = 'cnt', data = bike_dataframe)\n",
    "plt.subplot(2,4,5)\n",
    "sns.boxplot(x = 'holiday', y = 'cnt', data = bike_dataframe)\n",
    "plt.subplot(2,4,6)\n",
    "sns.boxplot(x = 'workingday', y = 'cnt', data = bike_dataframe)\n",
    "plt.subplot(2,4,7)\n",
    "sns.boxplot(x = 'yr', y = 'cnt', data = bike_dataframe)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create barplot related to categorical columns\n",
    "\n",
    "def plt_catgy_columns(column):\n",
    "    plt.figure(figsize = (12,6))\n",
    "    plt.subplot(1,2,1)\n",
    "    sns.barplot(x=column,y='cnt',data=bike_dataframe)\n",
    "    plt.subplot(1,2,2)\n",
    "    sns.barplot(x=column,y='cnt',data=bike_dataframe, hue='yr',palette='Set1')\n",
    "    plt.legend(labels=['2018', '2019'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting visualization for season column\n",
    "\n",
    "plt_catgy_columns('season')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fall seems to have more traction to booking. Furthermore, in each season, count of bookings has increased rapidly from 2018 to 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting visualization for month column\n",
    "\n",
    "plt_catgy_columns('mnth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum of bookings has been done between the months of May to Oct, following which the booking trend has decreased until the end of the year. And comparatively number of bookings have tremendously increased in the year 2019 from 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting visualization for weathersit column\n",
    "\n",
    "plt_catgy_columns('weathersit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the above graphs, it seems obvious that clear weather attracted more bookings, while standing with same conclusion that with each weather state, 2019 has seen more number of bookings than that of 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting visualization for weekday column\n",
    "\n",
    "plt_catgy_columns('weekday')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It is natural to notice to conclude that end of the week - Thurs, Fri and Sat, sees more bookings than rest of the days, same goes with the conclusion in the year 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting visualization for holiday column\n",
    "\n",
    "plt_catgy_columns('holiday')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It is very evident that bookings have enormous increase in its count on holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting visualization for workingday column\n",
    "\n",
    "plt_catgy_columns('workingday')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is slight increase with bookings on the working day, which may imply that customers might prefer to pick a bike for their work more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting visualization for year column\n",
    "\n",
    "plt_catgy_columns('yr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clear evidence that year 2019 has attracted more bookings than year 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysing/visualizing the numerical columns\n",
    "\n",
    "sns.pairplot(data=bike_dataframe,vars=['temp','atemp','hum','windspeed','cnt'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the correlation between the numerical variables\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "matrix = np.triu(bike_dataframe[['temp','atemp','hum','windspeed','cnt']].corr())\n",
    "sns.heatmap(bike_dataframe[['temp','atemp','hum','windspeed','cnt']].corr(), annot = True, cmap=\"RdYlGn\", mask=matrix)\n",
    "plt.title(\"Correlation between Numerical Variables\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The realtionship between 'temp' and 'atemp' are highly linear and hence these two parameters cannot be used together in model building due to multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy variable creation for month, weekday, weathersit and season variables.\n",
    "\n",
    "months_df=pd.get_dummies(bike_dataframe.mnth,drop_first=True)\n",
    "weekdays_df=pd.get_dummies(bike_dataframe.weekday,drop_first=True)\n",
    "weathersit_df=pd.get_dummies(bike_dataframe.weathersit,drop_first=True)\n",
    "seasons_df=pd.get_dummies(bike_dataframe.season,drop_first=True)\n",
    "\n",
    "bike_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging  the dataframe, with the dummy variable dataset. \n",
    "\n",
    "df_new = pd.concat([bike_dataframe,months_df,weekdays_df,weathersit_df,seasons_df],axis=1)\n",
    "\n",
    "# dropping unnecessary columns as we have already created dummy variable out of it.\n",
    "\n",
    "df_new.drop(['season','mnth','weekday','weathersit'], axis = 1, inplace = True)\n",
    "\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting new dataframe into Train and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataframe into Train and Test\n",
    "\n",
    "np.random.seed(0)\n",
    "df_train, df_test = train_test_split(df_new, train_size = 0.7, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape of training datatset\n",
    "\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape of testing datatset\n",
    "\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using MinMaxScaler to Rescaling the features\n",
    "\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifying the head of dataset before scaling.\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply scaler() to all the columns except the 'yes-no' and 'dummy' variables\n",
    "\n",
    "num_vars = ['temp','atemp','hum','windspeed','cnt']\n",
    "df_train[num_vars] = scaler.fit_transform(df_train[num_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifying the head after appying scaling.\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describing the dataset\n",
    "\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the correlation coefficients to see which variables are highly correlated\n",
    "\n",
    "plt.figure(figsize = (25,25))\n",
    "matrix = np.triu(df_train.corr())\n",
    "sns.heatmap(df_train.corr(), annot = True, cmap=\"RdYlGn\", mask=matrix)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cnt seems to have correlation with year variable and temp. Similarly, Misty and humidity show correlation. Spring season with Jan and Feb month, Summer season with may month and Winter season with oct and nov month show good correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing one of the correlation to see the trends via Scatter plot.\n",
    "\n",
    "plt.figure(figsize=[6,6])\n",
    "plt.scatter(df_train.temp, df_train.cnt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the above plot confirms positive correlation between temp and cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Linear Model\n",
    "\n",
    "y_train = df_train.pop('cnt')\n",
    "X_train = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive feature elimination \n",
    "\n",
    "ridgem = Ridge()\n",
    "ridgem.fit(X_train, y_train)\n",
    "\n",
    "rfe = RFE(ridgem,n_features_to_select=15)\n",
    "rfe = rfe.fit(X_train, y_train)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = rfe.support_\n",
    "\n",
    "# Print the selected features\n",
    "print(\"Selected Features:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns selected by RFE and their weights\n",
    "list(zip(X_train.columns,rfe.support_,rfe.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the selected variable via RFE in col list\n",
    "\n",
    "col = X_train.columns[rfe.support_]\n",
    "# col = ['yr', 'holiday', 'temp', 'atemp', 'hum', 'windspeed', 'dec', 'jan',\n",
    "       # 'july', 'nov', 'sep', 'Light_snowrain', 'Misty', 'spring', 'winter']\n",
    "print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking which columns has been rejected\n",
    "\n",
    "X_train.columns[~rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic function to calculate VIF of variables\n",
    "\n",
    "def calculateVIF(df):\n",
    "    # df1 = X_train[cols]\n",
    "    vif = pd.DataFrame()\n",
    "    vif['Features'] = df.columns\n",
    "    vif['VIF'] = [variance_inflation_factor(df.values.astype(float), i) for i in range(df.shape[1])]\n",
    "    vif['VIF'] = round(vif['VIF'], 2)\n",
    "    vif = vif.sort_values(by = \"VIF\", ascending = False)\n",
    "    return vif "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe with RFE selected variables\n",
    "\n",
    "X_train_rfe = X_train[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate VIF\n",
    "\n",
    "calculateVIF(X_train_rfe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### humidity shows high VIF value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building 1st linear regression model\n",
    "\n",
    "X_train_lm_1 = sm.add_constant(X_train_rfe)\n",
    "lr_1 = sm.OLS(y_train,X_train_lm_1.astype(float)).fit()\n",
    "print(lr_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As humidity shows high VIF values hence we can drop it\n",
    "X_train_new = X_train_rfe.drop(['hum'], axis = 1)\n",
    "\n",
    "# Run the function to calculate VIF for the new model\n",
    "calculateVIF(X_train_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking further if any more features can be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building 2nd linear regression model\n",
    "\n",
    "X_train_lm_2 = sm.add_constant(X_train_new)\n",
    "lr_2 = sm.OLS(y_train,X_train_lm_2.astype(float)).fit()\n",
    "print(lr_2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can drop nov variable as it has high p-value\n",
    "X_train_new = X_train_new.drop(['nov'], axis = 1)\n",
    "\n",
    "# Run the function to calculate VIF for the new model\n",
    "calculateVIF(X_train_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After dropping two features, there is no change in the VIF. Hence proceeding with further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building 3rd linear regression model\n",
    "\n",
    "X_train_lm_3 = sm.add_constant(X_train_new)\n",
    "lr_3 = sm.OLS(y_train,X_train_lm_3.astype(float)).fit()\n",
    "print(lr_3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can drop dec variable as it has high p-value\n",
    "X_train_new = X_train_new.drop(['dec'], axis = 1)\n",
    "\n",
    "# Run the function to calculate VIF for the new model\n",
    "calculateVIF(X_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building 4th linear regression model\n",
    "\n",
    "X_train_lm_4 = sm.add_constant(X_train_new)\n",
    "lr_4 = sm.OLS(y_train,X_train_lm_4.astype(float)).fit()\n",
    "print(lr_4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can drop jan variable as it has high p-value\n",
    "X_train_new = X_train_new.drop(['jan'], axis = 1)\n",
    "\n",
    "# Run the function to calculate VIF for the new model\n",
    "calculateVIF(X_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building 5th linear regression model\n",
    "\n",
    "X_train_lm_5 = sm.add_constant(X_train_new)\n",
    "lr_5 = sm.OLS(y_train,X_train_lm_5.astype(float)).fit()\n",
    "print(lr_5.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can drop july variable as it has high p-value\n",
    "X_train_new = X_train_new.drop(['july'], axis = 1)\n",
    "\n",
    "# Run the function to calculate VIF for the new model\n",
    "calculateVIF(X_train_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VIF seems to feasible now with all values below 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building 6th linear regression model\n",
    "\n",
    "X_train_lm_6 = sm.add_constant(X_train_new)\n",
    "lr_6 = sm.OLS(y_train,X_train_lm_6.astype(float)).fit()\n",
    "print(lr_6.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can cosider the above model i.e lr_6, as it seems to have very low multicolinearity between the predictors and the p-values for all the predictors seems to be significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F-Statistics value of 248.4 (which is greater than 1) and the p-value of 1.47e-186 i.e almost equals to zero, states that the overall model is significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the parameters and their coefficient values\n",
    "lr_6.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual Analysis of Train data and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = lr_6.predict(X_train_lm_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normality of error terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram of the error terms\n",
    "\n",
    "fig = plt.figure()\n",
    "sns.distplot((y_train - y_train_pred), bins = 20)\n",
    "fig.suptitle('Error Terms', fontsize = 20) \n",
    "plt.xlabel('Errors', fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### by observation, error terms is following nomral distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculateVIF(X_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "sns.heatmap(X_train_new.corr(),annot = True, cmap=\"RdYlGn\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clear from heat map that there is no multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear relationship validation using CCPR plot\n",
    "# Component and component plus residual plot\n",
    "\n",
    "sm.graphics.plot_ccpr(lr_6, 'temp')\n",
    "plt.show()\n",
    "\n",
    "sm.graphics.plot_ccpr(lr_6, 'sep')\n",
    "plt.show()\n",
    "\n",
    "sm.graphics.plot_ccpr(lr_6, 'windspeed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Homoscedasticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = lr_6.predict(X_train_lm_6)\n",
    "residual = y_train - y_train_pred\n",
    "sns.scatterplot(x=y_train, y=residual)\n",
    "plt.plot(y_train,(y_train - y_train), '-r')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Residual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No visible pattern observed from above plot for residuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Independence of residuals\n",
    "\n",
    "Durbin-Watson value of final model lr_6 is 2.085, which signifies there is no autocorrelation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Making Predictions Using the Final Model\n",
    "\n",
    "Now that we have fitted the model and checked the normality of error terms, it's time to go ahead and make predictions using the final, i.e. 6th model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying scaling on the test dataset\n",
    "\n",
    "num_vars = ['temp', 'atemp', 'hum', 'windspeed','cnt']\n",
    "df_test[num_vars] = scaler.transform(df_test[num_vars])\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = df_test.pop('cnt')\n",
    "X_test = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = X_train_new.columns\n",
    "\n",
    "X_test = X_test[col1]\n",
    "\n",
    "# Adding constant variable to test dataframe\n",
    "X_test_lm_6 = sm.add_constant(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_6.predict(X_test_lm_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, y_pred)\n",
    "round(r2,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Model Evaluation\n",
    "plot the graph for actual versus predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting y_test and y_pred to understand the spread\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(y_test, y_pred)\n",
    "fig.suptitle('y_test vs y_pred', fontsize = 20) \n",
    "plt.xlabel('y_test', fontsize = 18)\n",
    "plt.ylabel('y_pred', fontsize = 16) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(lr_6.params,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, the equation of best fitted line is:\n",
    "\n",
    "$ cnt = 0.1909 + 0.2341  *  year - 0.0963  *  holiday + 0.4777 * temp - 0.1481 * windspeed + 0.0910 * sep - 0.2850 * Light_snowrain - 0.0787 * Misty - 0.0554 * spring + 0.0621 * summer + 0.0945 * winter $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Adjusted-R^2 value for the test dataset\n",
    "\n",
    "adjusted_r2 = round(1-(1-r2)*(X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1),4)\n",
    "print(adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the fit on the test data\n",
    "# plotting a Regression plot\n",
    "\n",
    "plt.figure()\n",
    "sns.regplot(x=y_test.astype(float), y=y_pred.astype(float), ci=68, fit_reg=True,scatter_kws={\"color\": \"blue\"}, line_kws={\"color\": \"red\"})\n",
    "plt.title('y_test vs y_pred', fontsize=20)\n",
    "plt.xlabel('y_test', fontsize=18)\n",
    "plt.ylabel('y_pred', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing dataset comparison:\n",
    "    - Train dataset R^2          : 0.833\n",
    "    - Test dataset R^2           : 0.8038\n",
    "    - Train dataset Adjusted R^2 : 0.829    \n",
    "    - Test dataset Adjusted R^2  : 0.7944\n",
    "\n",
    "#### The real Factors which are attracting the demand of bikes are year, holiday, temp, windspeed, sep, Light_snowrain, Misty, spring, summer and winter. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
